Bias Detection and Explainability in AI Job Screening Models
ðŸ“‹ Project Overview
This project implements a comprehensive bias detection and explainability framework for AI-powered job screening systems. The analysis focuses on identifying, measuring, and mitigating gender bias in hiring decisions using structured candidate data and logistic regression models.

ðŸŽ¯ Challenge Objectives
Bias Detection: Identify and quantify gender bias in AI hiring models

Fairness Measurement: Calculate key fairness metrics (Demographic Parity, Equal Opportunity, Average Odds Difference)

Explainability: Use SHAP analysis to understand model decision-making patterns

Bias Mitigation: Implement reweighing techniques to reduce discriminatory outcomes

Trade-off Analysis: Evaluate the balance between model accuracy and fairness




